{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1e109f-b2f5-42a8-bcc3-0acf2d7af9a0",
   "metadata": {},
   "source": [
    "# modelforge.curate : Basic Usage\n",
    "\n",
    "This notebook will demonstrate basic usage of the `curate` module in modelforge, developed to make it easier to create modelforge compatible datasets with a uniform structure.  This module puts an emphasis of validation at the time of construction. \n",
    "\n",
    "In the curate module, we have 3 levels of hierarchy: \n",
    "\n",
    "- At the top most level, we have a dataset (i.e., an instance of `SourceDataset`)\n",
    "- A dataset contains records (instances of the `Record` class)\n",
    "- Each record contains properties (each property is defined as a Pydantic model that is a child of the `PropertyBaseModel` class)\n",
    "\n",
    "To start, let us import the packages we need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf4ef4a-d9b9-49bc-bd8a-3f5e62953c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelforge.curate import Record, SourceDataset\n",
    "from modelforge.curate.units import GlobalUnitSystem\n",
    "from modelforge.curate.properties import AtomicNumbers, Positions, Energies, Forces, MetaData\n",
    "\n",
    "from openff.units import unit\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb4ef7-18f9-41dd-9b08-14bb8afd88d7",
   "metadata": {},
   "source": [
    "### Set up a new dataset\n",
    "To start, we will create an instance of the `SourceDataset` class to store the dataset, providing a `name` for the dataset as a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad426d0-eb06-44b3-8ec5-7bb7cb016e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-07 11:40:22.968\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mmodelforge.curate.curate\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m481\u001b[0m - \u001b[33m\u001b[1mDatabase file test_dataset.sqlite already exists in ./. Removing it.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "new_dataset = SourceDataset(name=\"test_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae624b3-f5f1-4543-990d-be2a79697b04",
   "metadata": {},
   "source": [
    "### Create a record\n",
    "\n",
    "To create a record, we  instantiate the `Record` class providing a unique `name` as a string; this `name` will be used within the dataset to access/update records and thus needs to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f90876-3bc8-4e07-b2f7-b7e65242067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_mol1 = Record(name='mol1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ac0df-ff9d-4a73-ae5a-eef94ba7f17e",
   "metadata": {},
   "source": [
    "### Define properties\n",
    "The curate packages provides pydantic models for many common properties reported in datasets. \n",
    "\n",
    "Each record must include a few basic elements to be considered complete, namely:\n",
    "- atomic numbers\n",
    "- positions\n",
    "- energies\n",
    "  \n",
    "Records may of course contain other properties/metadata, but this is the minimal set of information required by modelforge during training. \n",
    "\n",
    "\n",
    "Note, properties are classified into four categories. These categories are used to validate the inputs (including the shape of the underlying arrays).  These classifications are also used within modelforge to know how to parse information from the dataset.  The four categories as as follows: \n",
    "- atomic_numbers -- array must have a shape (n_atoms,1); regardless of the number of configurations in a property, the atomic numbers must be consistent\n",
    "- per_system -- array must have a at least 2 dimensions, where the first dimensions (n_configs, X) -- Energy is an example of a per_system property with shape (n_configs, 1)\n",
    "- per_atom -- array must have at least 3 dimensions, where the first two dimensions correspond to (n_configs, n_atoms, X). Partial charge is an example of a per_atom property with shape (n_config, n_atoms, 1)\n",
    "- meta_data -- there are no shape requirements for meta_data, however, input is limited to (string, float, int, list, numpy_array)\n",
    "\n",
    "Users do not need to set the classification of a property for the pre-defined models within the module; the appropriate value is defined by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b381c6d-c740-48bb-af75-1a4c712bba8a",
   "metadata": {},
   "source": [
    "#### Defining atomic numbers\n",
    "Let us first start by considering how to initialize atomic numbers, in this case for an example CH molecule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587ce24b-4d72-40fb-a850-d0f85079178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_numbers = AtomicNumbers(value=np.array([[1], [6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f90255-9b73-44bc-a24b-bd21eabf6e32",
   "metadata": {},
   "source": [
    "The array that stores the atomic numbers must have the shape (n_atoms, 1).  An error will be raised if `len(value.shape) != 2` or `value.shape[1] != 1`. \n",
    "\n",
    "Properties can accept either a numpy array or a python list as input; the python list it will be converted to a numpy array automatically.  For example, the following syntax will produce an equivalent instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e19eb07-cb8d-4d5e-b54e-c18df911c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_numbers = AtomicNumbers(value=[[1], [6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefc0a9-9cde-4488-9f05-780c7856564d",
   "metadata": {},
   "source": [
    "#### Defining positions\n",
    "\n",
    "To define positions, we will use the `Positions` pydantic model.  Since positions must have units associated with them, they must also be set at the time of initialization; the model does not include a default unit. \n",
    "\n",
    "Units can be passed as an openff.units `Unit` or a string that can be understood by openff.units. An error will be raised if units are not defined, or if the units passed are not compatible (i.e., not a length measurement).\n",
    "\n",
    "Positions are a \"per_atom\" property storing the x,y, and z positions, and thus must be 3d array with shape (n_configs, n_atoms, 3).\n",
    "If `value.shape[2] !=3` or `len(value.shape) != 3`, this will raise an error.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5bcd450-3d52-4a45-ab1a-f107e11df202",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = Positions(\n",
    "    value=np.array([[[1.0, 1.0, 1.0], [2.0, 2.0, 2.0]]]), \n",
    "    units=\"nanometer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267df83-67d6-4a12-8ac3-d9a72a67b147",
   "metadata": {},
   "source": [
    "We can easily examine the positions, where we can see the `value`, `units`, `classification` and `property_type` (used to ensure unit compatibility); this also will determine the `n_configs` and `n_atoms` based on the shape of the underlying array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711bec10-63ec-44a8-a368-f38bd3bb3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='positions' value=array([[[1., 1., 1.],\n",
      "        [2., 2., 2.]]]) units=<Unit('nanometer')> classification='per_atom' property_type='length' n_configs=1 n_atoms=2\n"
     ]
    }
   ],
   "source": [
    "print(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b4f9e-62b8-42b5-8e79-429e133574b4",
   "metadata": {},
   "source": [
    "#### Defining energies \n",
    "To define energies, we will use the `Energies` pydantic model; as with positions, units must also be set.  \n",
    "\n",
    "Note, energy is a \"per_system\" property and thus the shape of the input array must be (n_configs, 1); an error will be raised if `value.shape[1] !=1` or `len(value.shape) != 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03c8a4f-a49f-444f-8b3c-252d7373e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = Energies(\n",
    "    value=np.array([[0.1]]), \n",
    "    units=unit.hartree\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9261ac4-ba1a-4b61-8ec6-14e6be08860c",
   "metadata": {},
   "source": [
    "#### Definiting meta data\n",
    "\n",
    "We can also provide meta data in the form of int, float, str, list, or numpy arrays.  These properties do not necessarily undergo any significant validation as this information is not used directly by modelforge. \n",
    "\n",
    "Below is an example of using the MetaData class to define the smiles of the molecule, passed as a string. \n",
    "\n",
    "Note, a SMILES property class could be defined that includes validation, e.g., passing the string to RDKit to ensure it is valid, however this has not been implemented at the current time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c9e150-a07f-4b31-bd77-654003983912",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = MetaData(name='smiles', value='[CH]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b6dc0-7fa4-4a72-aa01-57326899a7b2",
   "metadata": {},
   "source": [
    "#### Other properties\n",
    "\n",
    "Pydantic models have been defined for the following properties:\n",
    "- `atomic_numbers`\n",
    "- `Energies`\n",
    "- `Positions`\n",
    "- `Forces`\n",
    "- `PartialCharges`\n",
    "- `TotalCharge`\n",
    "- `SpinMultiplicities`\n",
    "- `DipoleMomentPerSystem`\n",
    "- `DipoleMomentPerAtom`\n",
    "- `DipoleMomentScalarPerSystem`\n",
    "- `QuadrupoleMomentPerSystem`\n",
    "- `QuadrupoleMomentPerAtom`\n",
    "- `OctupoleMomentPerAtom`\n",
    "- `Polarizability`\n",
    "- `BondOrders`\n",
    "- `MetaData`\n",
    "\n",
    "Note, each of thes emodels inherits from a more general `PropertyBaseClass` pydantic model; this model can be used to define any additional properties, but requires the user to provide the classification (e.g., per_atom, per_system) and the property_type (for the purposes of unit conversion, e.g., length, energy, force, charge, etc.). \n",
    "\n",
    "Classes for additional properties can be added to the module as well; this set was generated based on what was encountered within the current datasets supported by `modelforge`.\n",
    "\n",
    "##### More information on defining properties is provided in the \"defining_properties.ipynb\" notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42293f-4a96-42ef-adb5-8fe12c6ef045",
   "metadata": {},
   "source": [
    "### Add properties to a record\n",
    "\n",
    "Having defined properties we can now add them to the record. Properties can be added individually to the record or provided as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72291451-a62f-4780-b981-8fcd4127a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_mol1.add_property(atomic_numbers)\n",
    "record_mol1.add_properties([positions,energies, smiles])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee9344-8ba6-4db8-aaa2-5a2811bde1bc",
   "metadata": {},
   "source": [
    "By default when instantiating a new `Record` instance, `append_property = False`.\n",
    "If `append_property == False`, an error will be raised if you try to add a property with the same name more than once to the same record. This ensures we do not accidentally overwrite data in a record.\n",
    "\n",
    "They following will produce a ValueError because \"energies\" have already been set for the record.  Note, in all cases, atomic_numbers can only be set once, regardless of the state of append_property, as it is a unique case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf4f58d-502a-48ee-baec-e1fb99e094b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Property with name energies already exists in the record mol1.Set append_property=True to append to the existing property.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrecord_mol1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_property\u001b[49m\u001b[43m(\u001b[49m\u001b[43menergies\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/modelforge/modelforge-curate/modelforge/curate/curate.py:413\u001b[0m, in \u001b[0;36mRecord.add_property\u001b[0;34m(self, property)\u001b[0m\n\u001b[1;32m    409\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProperty with name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mproperty\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists in the record \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet append_property=True to append to the existing property.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m     )\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mper_system[\u001b[38;5;28mproperty\u001b[39m\u001b[38;5;241m.\u001b[39mname]\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mproperty\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    418\u001b[0m )\n\u001b[1;32m    419\u001b[0m temp_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mproperty\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mValueError\u001b[0m: Property with name energies already exists in the record mol1.Set append_property=True to append to the existing property."
     ]
    }
   ],
   "source": [
    "record_mol1.add_property(energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81920b1c-1101-4148-9051-2a7c40f8b5ef",
   "metadata": {},
   "source": [
    "## Validating a record\n",
    "\n",
    "The use of pydantic allows for considerable validation at the time of initialization of the properties, e.g., ensuring units have been set, compatibility of units, and minimal examination of the shape of the input array.  However, since each property is defined separately, we are unable to cross validate n_atoms and n_configs until those properties are grouped into a record. \n",
    "\n",
    "An individual record can be validated to ensure consistency of n_configs and n_atoms.  Since this minimal only has 3 properties, this checks that n_atoms in `atomic_numbers` matches `positions` and n_configs matches in `energies` and `positions`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00a9191-1345-4923-8a9a-f052b8a518db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_mol1.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962b873e-587b-47c9-be6c-3af3ced73cea",
   "metadata": {},
   "source": [
    "### Viewing a record\n",
    "Printing a record provides a summary of the contents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf96ffd4-de45-427c-9937-19a3ab60bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: mol1\n",
      "* n_atoms: 2\n",
      "* n_configs: 1\n",
      "* atomic_numbers:\n",
      " -  name='atomic_numbers' value=array([[1],\n",
      "       [6]]) units=<Unit('dimensionless')> classification='atomic_numbers' property_type='atomic_numbers' n_configs=None n_atoms=2\n",
      "* per-atom properties: (['positions']):\n",
      " -  name='positions' value=array([[[1., 1., 1.],\n",
      "        [2., 2., 2.]]]) units=<Unit('nanometer')> classification='per_atom' property_type='length' n_configs=1 n_atoms=2\n",
      "* per-system properties: (['energies']):\n",
      " -  name='energies' value=array([[0.1]]) units=<Unit('hartree')> classification='per_system' property_type='energy' n_configs=1 n_atoms=None\n",
      "* meta_data: (['smiles'])\n",
      " -  name='smiles' value='[CH]' units=<Unit('dimensionless')> classification='meta_data' property_type='meta_data' n_configs=None n_atoms=None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(record_mol1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3cbc9-c4c0-4990-8b0a-adb675a20e0c",
   "metadata": {},
   "source": [
    "The record can also be exported to a dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a2bed3-e521-49ae-a2ef-2ecd58d15b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mol1',\n",
       " 'n_atoms': 2,\n",
       " 'n_configs': 1,\n",
       " 'atomic_numbers': AtomicNumbers(name='atomic_numbers', value=array([[1],\n",
       "        [6]]), units=<Unit('dimensionless')>, classification='atomic_numbers', property_type='atomic_numbers', n_configs=None, n_atoms=2),\n",
       " 'per_atom': {'positions': Positions(name='positions', value=array([[[1., 1., 1.],\n",
       "          [2., 2., 2.]]]), units=<Unit('nanometer')>, classification='per_atom', property_type='length', n_configs=1, n_atoms=2)},\n",
       " 'per_system': {'energies': Energies(name='energies', value=array([[0.1]]), units=<Unit('hartree')>, classification='per_system', property_type='energy', n_configs=1, n_atoms=None)},\n",
       " 'meta_data': {'smiles': MetaData(name='smiles', value='[CH]', units=<Unit('dimensionless')>, classification='meta_data', property_type='meta_data', n_configs=None, n_atoms=None)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_mol1.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da729abe-5559-466a-8c1a-54de47957969",
   "metadata": {},
   "source": [
    "## Add a record to a dataset\n",
    "\n",
    "To add a record to the dataset, we use the `add_record` function of `SourceDataset`.\n",
    "\n",
    "Note, the `name` field of the record is used as a unique identifier.  You cannot add two records with the same `name`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56329f06-7440-44e9-82aa-4a1a38e1b874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_dataset.add_record(record_mol1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e523c-68bf-4271-a431-ea7e7532dae5",
   "metadata": {},
   "source": [
    "The entire dataset can validated.  This essentially just calls the validate function on the individual records, as well as ensure that the minimal set of properties exist (atomic_numbers, energies, and positions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bac9ccc5-867a-4f54-a2ea-4f74cebb6cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 253.16it/s]\n",
      "\u001b[32m2025-03-07 11:40:35.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodelforge.curate.curate\u001b[0m:\u001b[36mvalidate_records\u001b[0m:\u001b[36m1180\u001b[0m - \u001b[1mAll records validated successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.validate_records()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14815ba2-8dac-4d0b-95c6-013f9403fe99",
   "metadata": {},
   "source": [
    "### Saving to an HDF5 file\n",
    "\n",
    "To save ths to an hdf5 file, we call the `to_hdf5` function of the `SourceDataset` class, passing the output path and filename. This will automatically perform the validation discussed above before we write to the file. \n",
    "\n",
    "Additionally, when writing the file, it will convert records to a consistent unit system (by default, kilojoules_per_mole and nanometers are the base unit system for energy and distance), as defined by the `GlobalUnitSystem` class (discussed below).\n",
    "\n",
    "Note this returns the md5 checksum of the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f32cd4f-330d-4ebf-a27f-1a36b6751103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-07 11:40:37.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodelforge.curate.curate\u001b[0m:\u001b[36mto_hdf5\u001b[0m:\u001b[36m1312\u001b[0m - \u001b[1mValidating records\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 608.49it/s]\n",
      "\u001b[32m2025-03-07 11:40:37.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodelforge.curate.curate\u001b[0m:\u001b[36mvalidate_records\u001b[0m:\u001b[36m1180\u001b[0m - \u001b[1mAll records validated successfully.\u001b[0m\n",
      "\u001b[32m2025-03-07 11:40:37.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodelforge.curate.curate\u001b[0m:\u001b[36mto_hdf5\u001b[0m:\u001b[36m1315\u001b[0m - \u001b[1mWriting records to .//test_dataset.hdf5\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 423.92it/s]\n"
     ]
    }
   ],
   "source": [
    "checksum = new_dataset.to_hdf5(file_path=\"./\", file_name=\"test_dataset.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d3c511-e525-4eee-bd5c-3aa00b38847d",
   "metadata": {},
   "source": [
    "## Unit system and unit validation\n",
    "\n",
    "When defining individual properties, units are also validated.  When defining a property, users can specify any unit that is:\n",
    "- (1) supported by openff.units\n",
    "- (2) compatible with the parameter type (i.e., Positions expect a unit of length).\n",
    "\n",
    "Bullet 2 is assessed by comparing to the default values in the `GlobalUnitSystem` class (note, we are not making any unit conversions at the point of initializing a record, just checking for compatibility). \n",
    "\n",
    "The following will fail validation because we expect positions to be defined in distance units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08fe229e-be4c-4648-80d8-8f0143aa8021",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Positions\n  Value error, Unit angstrom ** 2 of positions are not compatible with the property type length.\n [type=value_error, input_value={'value': [[[1.0, 1.0, 1....<Unit('angstrom ** 2')>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mPositions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mangstrom\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mangstrom\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/modelforge311/lib/python3.11/site-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Positions\n  Value error, Unit angstrom ** 2 of positions are not compatible with the property type length.\n [type=value_error, input_value={'value': [[[1.0, 1.0, 1....<Unit('angstrom ** 2')>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error"
     ]
    }
   ],
   "source": [
    "pos = Positions(value=[[[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 3.0]]], units=unit.angstrom*unit.angstrom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085f29a-b005-4e2b-8dcb-86c58e1fca19",
   "metadata": {},
   "source": [
    "Units are stored as class attributes within the `GlobalUnitSystem` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4684a979-8564-4639-96c4-806c0ab55a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area : nanometer ** 2\n",
      "atomic_numbers : dimensionless\n",
      "charge : elementary_charge\n",
      "dimensionless : dimensionless\n",
      "dipole_moment : elementary_charge * nanometer\n",
      "energy : kilojoule_per_mole\n",
      "force : kilojoule_per_mole / nanometer\n",
      "frequency : gigahertz\n",
      "heat_capacity : kilojoule_per_mole / kelvin\n",
      "length : nanometer\n",
      "name : default\n",
      "octupole_moment : elementary_charge * nanometer ** 3\n",
      "polarizability : nanometer ** 3\n",
      "quadrupole_moment : elementary_charge * nanometer ** 2\n",
      "wavenumber : 1 / centimeter\n"
     ]
    }
   ],
   "source": [
    "from modelforge.curate.curate import GlobalUnitSystem\n",
    "print(GlobalUnitSystem())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbcb58d-ac94-48ae-b234-dbf07b644f33",
   "metadata": {},
   "source": [
    "Since these are class attributes, not instance variables, any changes or additions to the `GlobalUnitSystem `will apply to all usages within the script. For example, the following will change the units for length to angstroms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a1259d-3b2c-46df-b7ce-0d26ea572282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angstrom\n"
     ]
    }
   ],
   "source": [
    "GlobalUnitSystem.set_global_units('length', unit.angstrom)\n",
    "\n",
    "print(GlobalUnitSystem.get_units('length'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891f20e-2a77-431f-9c2d-53ba18725d35",
   "metadata": {},
   "source": [
    "The `set_global_units` function can also be used to add in a new property_type and associated units.  For example, the following would add pressure as a possible property_type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97b5878b-9ad7-4bef-97af-79031c5ea269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_atmosphere\n"
     ]
    }
   ],
   "source": [
    "GlobalUnitSystem.set_global_units('pressure', unit.atmosphere)\n",
    "\n",
    "print(GlobalUnitSystem.get_units('pressure'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269126d-10c9-482b-bf45-91fa906b2207",
   "metadata": {},
   "source": [
    "Changing the global unit system, e.g., making the nonsensical choice to set length to an energy unit, results in the validation to fail when defining positions with the units of angstrom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1fcc5e4-350c-4b37-bbcf-49d77f9c017a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Positions\n  Value error, Unit angstrom of positions are not compatible with the property type length.\n [type=value_error, input_value={'value': [[[1.0, 1.0, 1....ts': <Unit('angstrom')>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m GlobalUnitSystem\u001b[38;5;241m.\u001b[39mset_global_units(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m.\u001b[39mhartree)\n\u001b[0;32m----> 2\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mPositions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mangstrom\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/modelforge311/lib/python3.11/site-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Positions\n  Value error, Unit angstrom of positions are not compatible with the property type length.\n [type=value_error, input_value={'value': [[[1.0, 1.0, 1....ts': <Unit('angstrom')>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/value_error"
     ]
    }
   ],
   "source": [
    "GlobalUnitSystem.set_global_units('length', unit.hartree)\n",
    "pos = Positions(value=[[[1.0, 1.0, 1.0], [2.0, 2.0, 2.0], [3.0, 3.0, 3.0]]], units=unit.angstrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29ebda4c-cb79-42ed-bb34-05a264427d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalUnitSystem.set_global_units('length', unit.nanometer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d946a-668c-4cbe-9e9e-1ff43742f066",
   "metadata": {},
   "source": [
    "When hdf5 files are generated, quantities are automatically convert to the units specified in the `GlobalUnitSystem`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63ca3b-b33d-4918-94e8-48116d9e80d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
