[potential]
potential_name = "SchNet"

[potential.core_parameter]
number_of_radial_basis_functions = 20
maximum_interaction_radius = "5.0 angstrom"
number_of_interaction_modules = 3
number_of_filters = 32
shared_interactions = false
predicted_properties = ["per_atom_energy"]
predicted_dim = [1]

[potential.core_parameter.activation_function_parameter]
activation_function_name = "ShiftedSoftplus"

[potential.core_parameter.featurization]
properties_to_featurize = ['atomic_number']
[potential.core_parameter.featurization.atomic_number]
maximum_atomic_number = 101
number_of_per_atom_features = 32

[potential.postprocessing_parameter]
properties_to_process = ['per_atom_energy']
[potential.postprocessing_parameter.per_atom_energy]
normalize = true
from_atom_to_system_reduction = true
keep_per_atom_property = true
[potential.postprocessing_parameter.general_postprocessing_operation]
calculate_molecular_self_energy = true

[dataset]
dataset_name = "QM9"
version_select = "nc_1000_v1.1"
num_workers = 4
pin_memory = true
properties_of_interest = ["atomic_numbers", "positions", "internal_energy_at_0K", "dipole_moment_per_system"]
element_filter = []

[dataset.properties_assignment]
atomic_numbers = "atomic_numbers"
positions = "positions"
E = "internal_energy_at_0K"

[training]
number_of_epochs = 2
remove_self_energies = true
batch_size = 128
lr = 1e-3
monitor = "val/per_system_energy/rmse"
shift_center_of_mass_to_origin = false

[training.experiment_logger]
logger_name = "tensorboard"

[training.experiment_logger.tensorboard_configuration]
save_dir = "logs"

[training.lr_scheduler]
scheduler_name = "ReduceLROnPlateau"
frequency = 1
mode = "min"
factor = 0.1
patience = 10
cooldown = 5
min_lr = 1e-8
threshold = 0.1
threshold_mode = "abs"
interval = "epoch"

[training.loss_parameter]
loss_components = ['per_system_energy', 'per_atom_force'] # use

[training.loss_parameter.weight]
per_system_energy = 0.999 #NOTE: reciprocal units
per_atom_force = 0.001


[training.early_stopping]
verbose = true
min_delta = 0.001
patience = 50

[training.splitting_strategy]
name = "random_record_splitting_strategy"
data_split = [0.8, 0.1, 0.1]
seed = 42

[runtime]
verbose = true
save_dir = "lightning_logs"
experiment_name = "{potential_name}_{dataset_name}"
local_cache_dir = "./cache"
accelerator = "cpu"
number_of_nodes = 1
devices = 1                                         #[0,1,2,3]
checkpoint_path = "None"
simulation_environment = "PyTorch"
log_every_n_steps = 1
