[training]
number_of_epochs = 2
remove_self_energies = true
shift_center_of_mass_to_origin = false
batch_size = 128
lr = 5e-4
monitor = "val/per_system_energy/rmse" # Common monitor key
plot_frequency = 1
gradient_clip_val = 5.0
# ------------------------------------------------------------ #
[training.experiment_logger]
logger_name = "tensorboard" # this will set which logger to use
[training.experiment_logger.tensorboard_configuration]
save_dir = "logs"
# ------------------------------------------------------------ #
[training.experiment_logger.wandb_configuration]
save_dir = "logs"
project = "tests"
group = "exp00"
log_model = true
job_type = "testing"
tags = ["v_0.1.0"]
notes = "testing training"
# ------------------------------------------------------------ #
# Learning Rate Scheduler Configuration
[training.lr_scheduler]
scheduler_name = "ReduceLROnPlateau"
frequency = 1
interval = "epoch"
monitor = "val/per_system_energy/rmse"
mode = "min"
factor = 0.1
patience = 10
threshold = 0.1
threshold_mode = "abs"
cooldown = 5
min_lr = 1e-8
eps = 1e-8                             # Optional, default is 1e-8
# ------------------------------------------------------------ #
[training.loss_parameter]
loss_components = ['per_system_energy'] #, 'per_atom_force']
# ------------------------------------------------------------ #
[training.loss_parameter.weight]
per_system_energy = 1.0
# ------------------------------------------------------------ #
[training.early_stopping]
verbose = true
min_delta = 0.001
patience = 50
# ------------------------------------------------------------ #
[training.splitting_strategy]
name = "random_record_splitting_strategy"
data_split = [0.8, 0.1, 0.1]
seed = 42
# ------------------------------------------------------------ #
